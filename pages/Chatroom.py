from initialization import *
from langchain.schema import AIMessage, HumanMessage, SystemMessage
st.set_page_config(page_title="Chris Irag", page_icon="â™¿")


#llama-server --hf-repo bartowski/Phi-3.5-mini-instruct-GGUF --hf-file Phi-3.5-mini-instruct-Q4_0_4_4.gguf -c 4096

if 'main_init' not in st.session_state:
    st.session_state['main_init'] = False

if 'chat_option' not in st.session_state:
    st.session_state['chat_option'] = None

if not st.session_state['main_init']:
    st.markdown("""
    # Chatroom
    ### by Chris Irag, DS3A
    
    ***
    """)
    this_option = st.selectbox(
    "Who would you like to talk to?",
    ("OpenAI", "MistralAI", "Gemini", "Phi", "Llama"),
    index=None,
    placeholder="Select Chatbot",
    key=303
    )



    enable_switching_init = True if this_option == None else False
    init_chat = st.button("Chat Now", disabled=enable_switching_init, help='Choose a chatbot to chat with')
    
    if init_chat:
        st.session_state['chat_option'] = this_option
        st.session_state['main_init'] = True
        st.rerun()
    
def init_session_vars(llm_name, prompt_schema=[]):
    st.header(f"{chat}")
    if f'{llm_name}_history' not in st.session_state:
        st.session_state[f"{llm_name}_history"] = []

    # instantiating a list to store the whole conversation so far for giving context and memory for the LLM
    if f"{llm_name}_messages" not in st.session_state:
        st.session_state[f"{llm_name}_messages"] = prompt_schema

if st.session_state['chat_option'] == "OpenAI":
    chat = st.session_state['chat_option']
    from OpenAI import display_chat_history
    from OpenAI import ask_openai as ask_llm
    init_session_vars("OpenAI", [SystemMessage(content="You are a helpful assistant.")])

if st.session_state['chat_option'] == "MistralAI":
    chat = st.session_state['chat_option']
    from MistralAI import display_chat_history
    from MistralAI import ask_mistralai as ask_llm
    init_session_vars("MistralAI", [("system", "You are a helpful assistant.")])

if st.session_state['chat_option'] == "Gemini":
    chat = st.session_state['chat_option']
    from Gemini import display_chat_history
    from Gemini import ask_gemini as ask_llm
    init_session_vars("Gemini", [])

if st.session_state['chat_option'] == "Phi":
    chat = st.session_state['chat_option']
    from Phi import display_chat_history
    from Phi import ask_phi as ask_llm
    init_session_vars("Phi", [{"role": "system", "content": 'You are a helpful assistant.'}])

####

if st.session_state['main_init']:
    try:
        option = st.sidebar.selectbox(
            "Switch chatbot",
            ("OpenAI", "MistralAI", "Gemini", "Phi", "Llama"),
            index=None,
            placeholder="Switch Chatbot",
            key=302,
            label_visibility="collapsed"
        ) 

        enable_switching = True if option == None else False
        switch_chat = st.sidebar.button("Switch Now", disabled=enable_switching, help='Choose a chatbot to switch to')
        
        if switch_chat:
            st.session_state['chat_option'] = option
            st.rerun()

        st.sidebar.markdown(" *** ")
        st.sidebar.header("Chat Settings")
        st.session_state["toggle_display_metadata"] = st.sidebar.toggle("Enable Response Metadata")
        st.session_state["toggle_display_timestamp"] = st.sidebar.toggle("Enable Message Age")

        user_query = st.chat_input(f"Ask {chat}")

        if user_query != None:
            start_time = time.time()
            answer = ask_llm(user_query)
            end_time = time.time()
            st.session_state[f'{chat}_history'].append((user_query, (start_time, end_time), answer))

        display_chat_history(response_metadata=st.session_state["toggle_display_metadata"], message_age=st.session_state["toggle_display_timestamp"])
    
    except Exception as e:
        st.error(f"An error occurred: {str(e)}")
        st.info("""
        ## Please ...

        ### Report

        - If you think this is a bug.

        """)
        st.link_button("Report a Bug", "Report_a_Bug", type="primary")

        st.info("""
        ### Wait
        - Service is not available and should be available soon.
        - If this feature is yet to be supported.
        """)
        